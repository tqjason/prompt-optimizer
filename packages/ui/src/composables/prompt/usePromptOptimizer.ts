import { ref, nextTick, computed, reactive, type Ref, type ComputedRef } from 'vue'

import { useToast } from '../ui/useToast'
import { useI18n } from 'vue-i18n'
import { getErrorMessage } from '../../utils/error'

import { v4 as uuidv4 } from 'uuid'
import type {
  IModelManager,
  IHistoryManager,
  Template,
  PromptRecordChain,
  PromptRecordType,
  IPromptService,
  ITemplateManager,
  OptimizationMode,
  OptimizationRequest,
  ConversationMessage,
  ToolDefinition,
} from '@prompt-optimizer/core'
import type { AppServices } from '../../types/services'
import { useFunctionMode, type FunctionMode } from '../mode'


type PromptChain = PromptRecordChain

interface AdvancedContextPayload {
  variables: Record<string, string>
  messages?: ConversationMessage[]
  tools?: ToolDefinition[]
}

/**
 * æç¤ºè¯ä¼˜åŒ–å™¨Hook
 * @param services æœåŠ¡å®ä¾‹å¼•ç”¨
 * @param optimizationMode å½“å‰ä¼˜åŒ–æ¨¡å¼ï¼ˆä» basicSubMode/proSubMode è®¡ç®—å¾—å‡ºçš„ computedï¼‰
 * @param selectedOptimizeModel ä¼˜åŒ–æ¨¡å‹é€‰æ‹©
 * @param selectedTestModel æµ‹è¯•æ¨¡å‹é€‰æ‹©
 * @param contextMode ä¸Šä¸‹æ–‡æ¨¡å¼ï¼ˆç”¨äºå˜é‡æ›¿æ¢ç­–ç•¥ï¼Œå…¼å®¹æ€§ä¿ç•™ï¼‰
 * @returns æç¤ºè¯ä¼˜åŒ–å™¨æ¥å£
 * @deprecated optimizationMode å‚æ•°å»ºè®®ä¼ å…¥ computed å€¼ï¼ˆä» basicSubMode/proSubMode åŠ¨æ€è®¡ç®—ï¼‰
 */
type OptimizationModeSource = Ref<OptimizationMode> | ComputedRef<OptimizationMode>

export function usePromptOptimizer(
  services: Ref<AppServices | null>,
  optimizationMode: OptimizationModeSource,    // å¿…éœ€å‚æ•°ï¼Œæ¥å— computed
  selectedOptimizeModel?: Ref<string>,                 // ä¼˜åŒ–æ¨¡å‹é€‰æ‹©
  selectedTestModel?: Ref<string>,                     // æµ‹è¯•æ¨¡å‹é€‰æ‹©
  contextMode?: Ref<import('@prompt-optimizer/core').ContextMode>  // ä¸Šä¸‹æ–‡æ¨¡å¼
) {
  const optimizeModel = selectedOptimizeModel || ref('')
  const testModel = selectedTestModel || ref('')
  const toast = useToast()
  const { t } = useI18n()
  
  // æœåŠ¡å¼•ç”¨
  const modelManager = computed(() => services.value?.modelManager)
  const templateManager = computed(() => services.value?.templateManager)
  const historyManager = computed(() => services.value?.historyManager)
  const promptService = computed(() => services.value?.promptService)
  const { functionMode } = useFunctionMode(services)
  
  // ä½¿ç”¨ reactive åˆ›å»ºä¸€ä¸ªå“åº”å¼çŠ¶æ€å¯¹è±¡ï¼Œè€Œä¸æ˜¯å•ç‹¬çš„ ref
  const state = reactive({
    // çŠ¶æ€
    prompt: '',
    optimizedPrompt: '',
    optimizedReasoning: '', // ä¼˜åŒ–æ¨ç†å†…å®¹
    isOptimizing: false,
    isIterating: false,
    selectedOptimizeTemplate: null as Template | null,  // ç³»ç»Ÿæç¤ºè¯ä¼˜åŒ–æ¨¡æ¿
    selectedUserOptimizeTemplate: null as Template | null,  // ç”¨æˆ·æç¤ºè¯ä¼˜åŒ–æ¨¡æ¿
    selectedIterateTemplate: null as Template | null,
    currentChainId: '',
    currentVersions: [] as PromptChain['versions'],
  currentVersionId: '',
  
  // æ–¹æ³• (å°†åœ¨ä¸‹é¢å®šä¹‰å¹¶ç»‘å®šåˆ° state)
  handleOptimizePrompt: async () => {},
  handleOptimizePromptWithContext: async (_advancedContext: AdvancedContextPayload) => {},
  handleIteratePrompt: async (payload: { originalPrompt: string, optimizedPrompt: string, iterateInput: string }) => {},
  saveLocalEdit: async (_payload: { optimizedPrompt: string; note?: string; source?: 'patch' | 'manual' }) => {},
  handleSwitchVersion: async (version: PromptChain['versions'][number]) => {},
  handleAnalyze: () => {}
})
  
  // æ³¨æ„ï¼šå­˜å‚¨é”®ç°åœ¨ç”± useTemplateManager ç»Ÿä¸€ç®¡ç†
  
  // ä¼˜åŒ–æç¤ºè¯
  state.handleOptimizePrompt = async () => {
    if (!state.prompt.trim() || state.isOptimizing) return

    // æ ¹æ®ä¼˜åŒ–æ¨¡å¼é€‰æ‹©å¯¹åº”çš„æ¨¡æ¿
    const currentTemplate = optimizationMode.value === 'system' 
      ? state.selectedOptimizeTemplate 
      : state.selectedUserOptimizeTemplate

    if (!currentTemplate) {
      toast.error(t('toast.error.noOptimizeTemplate'))
      return
    }

    if (!optimizeModel.value) {
      toast.error(t('toast.error.noOptimizeModel'))
      return
    }

    // åœ¨å¼€å§‹ä¼˜åŒ–å‰ç«‹å³æ¸…ç©ºçŠ¶æ€ï¼Œç¡®ä¿æ²¡æœ‰ç«æ€æ¡ä»¶
    state.isOptimizing = true
    state.optimizedPrompt = ''  // å¼ºåˆ¶åŒæ­¥æ¸…ç©º
    state.optimizedReasoning = '' // å¼ºåˆ¶åŒæ­¥æ¸…ç©º
    
    // ç­‰å¾…ä¸€ä¸ªå¾®ä»»åŠ¡ç¡®ä¿çŠ¶æ€æ›´æ–°å®Œæˆ
    await nextTick()

    try {
      // æ„å»ºä¼˜åŒ–è¯·æ±‚
      const request: OptimizationRequest = {
        optimizationMode: optimizationMode.value,
        targetPrompt: state.prompt,
        templateId: currentTemplate.id,
        modelKey: optimizeModel.value,
        contextMode: contextMode?.value  // ä¼ é€’ä¸Šä¸‹æ–‡æ¨¡å¼
      }

      // ä½¿ç”¨é‡æ„åçš„ä¼˜åŒ–API
      await promptService.value!.optimizePromptStream(
        request,
        {
          onToken: (token: string) => {
            state.optimizedPrompt += token
          },
          onReasoningToken: (reasoningToken: string) => {
            state.optimizedReasoning += reasoningToken
          },
          onComplete: async () => {
            if (!currentTemplate) return

            try {
              // Create new record chain with enhanced metadataï¼ŒElectronProxyä¼šè‡ªåŠ¨å¤„ç†åºåˆ—åŒ–
              // ä¾æ® functionMode ä¸å½“å‰æ¨¡æ¿ç±»å‹å†³å®šå†å²è®°å½•ç±»å‹
              const isPro = (functionMode.value as FunctionMode) === 'pro'
              const baseType = (optimizationMode.value === 'system' ? 'optimize' : 'userOptimize') as PromptRecordType
              const recordType = (() => {
                if (isPro) {
                  return (optimizationMode.value === 'system' ? 'conversationMessageOptimize' : 'contextUserOptimize') as PromptRecordType
                }
                // å…¼å®¹ï¼šè‹¥é€‰æ‹©çš„æ˜¯ context æ¨¡æ¿ï¼ˆå³ä½¿å½“å‰æ¨¡å¼é proï¼‰ï¼Œä¹Ÿè®°å½•ä¸º context*
                const tplType = currentTemplate.metadata?.templateType
                if (tplType === 'conversationMessageOptimize' || tplType === 'contextUserOptimize') return tplType as PromptRecordType
                return baseType
              })()

              const recordData = {
                id: uuidv4(),
                originalPrompt: state.prompt,
                optimizedPrompt: state.optimizedPrompt,
                type: recordType,
                modelKey: optimizeModel.value,
                templateId: currentTemplate.id,
                timestamp: Date.now(),
                metadata: {
                  optimizationMode: optimizationMode.value,
                  functionMode: functionMode.value
                }
              };

              const newRecord = await historyManager.value!.createNewChain(recordData);

              state.currentChainId = newRecord.chainId;
              state.currentVersions = newRecord.versions;
              state.currentVersionId = newRecord.currentRecord.id;

              toast.success(t('toast.success.optimizeSuccess'))
            } catch (error: unknown) {
              console.error('åˆ›å»ºå†å²è®°å½•å¤±è´¥:', error)
              toast.error('åˆ›å»ºå†å²è®°å½•å¤±è´¥: ' + getErrorMessage(error))
            } finally {
              state.isOptimizing = false
            }
          },
          onError: (error: Error) => {
            console.error(t('toast.error.optimizeProcessFailed'), error)
            toast.error(error.message || t('toast.error.optimizeFailed'))
            state.isOptimizing = false
          }
        }
      )
    } catch (error: unknown) {
      console.error(t('toast.error.optimizeFailed'), error)
      toast.error(getErrorMessage(error) || t('toast.error.optimizeFailed'))
    } finally {
      state.isOptimizing = false
    }
  }
  
  // å¸¦ä¸Šä¸‹æ–‡çš„ä¼˜åŒ–æç¤ºè¯
  state.handleOptimizePromptWithContext = async (advancedContext: AdvancedContextPayload) => {
    // å¯¹äºç³»ç»Ÿæ¨¡å¼ï¼Œæ£€æŸ¥æ¶ˆæ¯è€Œä¸æ˜¯prompt
    const hasMessages = advancedContext.messages && Object.keys(advancedContext.messages).length > 0
    const hasPrompt = state.prompt.trim()

    // è‡³å°‘éœ€è¦æœ‰æ¶ˆæ¯æˆ–promptå…¶ä¸­ä¹‹ä¸€
    if ((!hasMessages && !hasPrompt) || state.isOptimizing) {
      console.log('[usePromptOptimizer] Skipping optimization:', { hasMessages, hasPrompt, isOptimizing: state.isOptimizing })
      return
    }

    // æ ¹æ®ä¼˜åŒ–æ¨¡å¼é€‰æ‹©å¯¹åº”çš„æ¨¡æ¿
    const currentTemplate = optimizationMode.value === 'system' 
      ? state.selectedOptimizeTemplate 
      : state.selectedUserOptimizeTemplate

    if (!currentTemplate) {
      toast.error(t('toast.error.noOptimizeTemplate'))
      return
    }

    if (!optimizeModel.value) {
      toast.error(t('toast.error.noOptimizeModel'))
      return
    }

    // åœ¨å¼€å§‹ä¼˜åŒ–å‰ç«‹å³æ¸…ç©ºçŠ¶æ€ï¼Œç¡®ä¿æ²¡æœ‰ç«æ€æ¡ä»¶
    state.isOptimizing = true
    state.optimizedPrompt = ''  // å¼ºåˆ¶åŒæ­¥æ¸…ç©º
    state.optimizedReasoning = '' // å¼ºåˆ¶åŒæ­¥æ¸…ç©º
    
    // ç­‰å¾…ä¸€ä¸ªå¾®ä»»åŠ¡ç¡®ä¿çŠ¶æ€æ›´æ–°å®Œæˆ
    await nextTick()

    try {
      // æ„å»ºå¸¦æœ‰é«˜çº§ä¸Šä¸‹æ–‡çš„ä¼˜åŒ–è¯·æ±‚
      // åœ¨ç³»ç»Ÿæ¨¡å¼ä¸‹ï¼Œå¦‚æœæ²¡æœ‰å•ç‹¬çš„promptï¼Œä½¿ç”¨æ¶ˆæ¯å†…å®¹ä½œä¸ºæè¿°
      const targetPrompt = state.prompt.trim() ||
        (advancedContext.messages && Object.keys(advancedContext.messages).length > 0
          ? t('toast.info.multiTurnOptimizationPrompt', { count: Object.keys(advancedContext.messages).length })
          : '');

      const request: OptimizationRequest = {
        optimizationMode: optimizationMode.value,
        targetPrompt,
        templateId: currentTemplate.id,
        modelKey: optimizeModel.value,
        contextMode: contextMode?.value,  // ä¼ é€’ä¸Šä¸‹æ–‡æ¨¡å¼
        // å…³é”®ï¼šæ·»åŠ é«˜çº§ä¸Šä¸‹æ–‡
        advancedContext: {
          variables: advancedContext.variables,
          messages: advancedContext.messages,
          tools: advancedContext.tools  // ğŸ†• æ·»åŠ å·¥å…·ä¼ é€’
        }
      }

      console.log('[usePromptOptimizer] Starting optimization with advanced context:', request.advancedContext)

      // ä½¿ç”¨é‡æ„åçš„ä¼˜åŒ–API
      await promptService.value!.optimizePromptStream(
        request,
        {
          onToken: (token: string) => {
            state.optimizedPrompt += token
          },
          onReasoningToken: (reasoningToken: string) => {
            state.optimizedReasoning += reasoningToken
          },
          onComplete: async () => {
            if (!currentTemplate) return

            // åˆ›å»ºå†å²è®°å½• - åŒ…å«ä¸Šä¸‹æ–‡ä¿¡æ¯
            try {
              const isPro = (functionMode.value as FunctionMode) === 'pro'
              const baseType = (optimizationMode.value === 'system' ? 'optimize' : 'userOptimize') as PromptRecordType
              const recordType = (() => {
                if (isPro) return (optimizationMode.value === 'system' ? 'conversationMessageOptimize' : 'contextUserOptimize') as PromptRecordType
                const tplType = currentTemplate.metadata?.templateType
                if (tplType === 'conversationMessageOptimize' || tplType === 'contextUserOptimize') return tplType as PromptRecordType
                return baseType
              })()

              const recordData = {
                id: uuidv4(),
                originalPrompt: targetPrompt,  // ä½¿ç”¨ targetPrompt è€Œä¸æ˜¯ state.prompt
                optimizedPrompt: state.optimizedPrompt,
                type: recordType,
                modelKey: optimizeModel.value,
                templateId: currentTemplate.id,
                timestamp: Date.now(),
                // æ·»åŠ ä¸Šä¸‹æ–‡ä¿¡æ¯åˆ°å†å²è®°å½•
                metadata: {
                  optimizationMode: optimizationMode.value,
                  functionMode: functionMode.value,
                  hasAdvancedContext: true,
                  variableCount: Object.keys(advancedContext.variables).length,
                  messageCount: advancedContext.messages?.length || 0,
                  conversationSnapshot: advancedContext.messages?.map(msg => ({
                    id: msg.id,
                    role: msg.role,
                    content: msg.content,
                    originalContent: msg.originalContent,
                    // è¿è¡Œæ—¶å±æ€§ï¼šæ¶ˆæ¯è¢«ä¼˜åŒ–ååŠ¨æ€æ·»åŠ çš„å…ƒæ•°æ®
                    chainId: (msg as Record<string, unknown>).chainId as string | undefined,
                    appliedVersion: (msg as Record<string, unknown>).appliedVersion as number | undefined
                  }))
                }
              };

              const newRecord = await historyManager.value!.createNewChain(recordData);

              state.currentChainId = newRecord.chainId;
              state.currentVersions = newRecord.versions;
              state.currentVersionId = newRecord.currentRecord.id;

              toast.success(t('toast.success.optimizeSuccess'))
            } catch (error: unknown) {
              console.error('åˆ›å»ºå†å²è®°å½•å¤±è´¥:', error)
              toast.error('åˆ›å»ºå†å²è®°å½•å¤±è´¥: ' + getErrorMessage(error))
            } finally {
              state.isOptimizing = false
            }
          },
          onError: (error: Error) => {
            console.error(t('toast.error.optimizeProcessFailed'), error)
            toast.error(error.message || t('toast.error.optimizeFailed'))
            state.isOptimizing = false
          }
        }
      )
    } catch (error: unknown) {
      console.error(t('toast.error.optimizeFailed'), error)
      toast.error(getErrorMessage(error) || t('toast.error.optimizeFailed'))
    } finally {
      state.isOptimizing = false
    }
  }
  
  // è¿­ä»£ä¼˜åŒ–
  state.handleIteratePrompt = async ({ originalPrompt, optimizedPrompt: lastOptimizedPrompt, iterateInput }: { originalPrompt: string, optimizedPrompt: string, iterateInput: string }) => {
    // ğŸ”§ ä¿®å¤ï¼šè¿­ä»£æ¨¡æ¿å®é™…ä¸Šä¸éœ€è¦ originalPromptï¼Œåªéœ€è¦ lastOptimizedPrompt å’Œ iterateInput
    // ç§»é™¤ !originalPrompt æ£€æŸ¥ï¼Œå…è®¸ç”¨æˆ·ç›´æ¥åœ¨å·¥ä½œåŒºç¼–è¾‘åè¿­ä»£
    if (!lastOptimizedPrompt || state.isIterating) return
    if (!iterateInput) return
    if (!state.selectedIterateTemplate) {
      toast.error(t('toast.error.noIterateTemplate'))
      return
    }

    // åœ¨å¼€å§‹è¿­ä»£å‰ç«‹å³æ¸…ç©ºçŠ¶æ€ï¼Œç¡®ä¿æ²¡æœ‰ç«æ€æ¡ä»¶
    state.isIterating = true
    state.optimizedPrompt = ''  // å¼ºåˆ¶åŒæ­¥æ¸…ç©º
    state.optimizedReasoning = '' // å¼ºåˆ¶åŒæ­¥æ¸…ç©º
    
    // ç­‰å¾…ä¸€ä¸ªå¾®ä»»åŠ¡ç¡®ä¿çŠ¶æ€æ›´æ–°å®Œæˆ
    await nextTick()
    
    try {
      await promptService.value!.iteratePromptStream(
        originalPrompt,
        lastOptimizedPrompt,
        iterateInput,
        optimizeModel.value,
        {
          onToken: (token: string) => {
            state.optimizedPrompt += token
          },
          onReasoningToken: (reasoningToken: string) => {
            state.optimizedReasoning += reasoningToken
          },
          onComplete: async (_response: unknown) => {
            if (!state.selectedIterateTemplate) {
              state.isIterating = false
              return
            }

            try {
              // ä½¿ç”¨æ­£ç¡®çš„addIterationæ–¹æ³•æ¥ä¿å­˜è¿­ä»£å†å²ï¼ŒElectronProxyä¼šè‡ªåŠ¨å¤„ç†åºåˆ—åŒ–
              const iterationData = {
                chainId: state.currentChainId,
                originalPrompt: originalPrompt,
                optimizedPrompt: state.optimizedPrompt,
                iterationNote: iterateInput,
                modelKey: optimizeModel.value,
                templateId: state.selectedIterateTemplate.id
              };

              const updatedChain = await historyManager.value!.addIteration(iterationData);

              state.currentVersions = updatedChain.versions
              state.currentVersionId = updatedChain.currentRecord.id

              toast.success(t('toast.success.iterateComplete'))
            } catch (error: unknown) {
              console.error('[History] è¿­ä»£è®°å½•å¤±è´¥:', error)
              toast.warning(t('toast.warning.historyFailed'))
            } finally {
              state.isIterating = false
            }
          },
          onError: (error: Error) => {
            console.error('[Iterate] è¿­ä»£å¤±è´¥:', error)
            toast.error(t('toast.error.iterateFailed'))
            state.isIterating = false
          }
        },
        state.selectedIterateTemplate.id
      )
    } catch (error: unknown) {
      console.error('[Iterate] è¿­ä»£å¤±è´¥:', error)
      toast.error(t('toast.error.iterateFailed'))
      state.isIterating = false
    }
  }

  /**
   * ä¿å­˜æœ¬åœ°ä¿®æ”¹ä¸ºä¸€ä¸ªæ–°ç‰ˆæœ¬ï¼ˆä¸è§¦å‘ LLMï¼‰
   * - ç”¨äºâ€œç›´æ¥ä¿®å¤â€ä¸æ‰‹åŠ¨ç¼–è¾‘åçš„æ˜¾å¼ä¿å­˜
   */
  state.saveLocalEdit = async ({ optimizedPrompt, note, source }: { optimizedPrompt: string; note?: string; source?: 'patch' | 'manual' }) => {
    try {
      if (!historyManager.value) throw new Error('History service unavailable')
      if (!optimizedPrompt) return

      const currentRecord = state.currentVersions.find(v => v.id === state.currentVersionId)
      const modelKey = currentRecord?.modelKey || optimizeModel.value || 'local-edit'
      const templateId =
        currentRecord?.templateId ||
        state.selectedIterateTemplate?.id ||
        (optimizationMode.value === 'system' ? state.selectedOptimizeTemplate?.id : state.selectedUserOptimizeTemplate?.id) ||
        'local-edit'

      // è‹¥å½“å‰æ²¡æœ‰é“¾ï¼ˆæå°‘æ•°åœºæ™¯ï¼‰ï¼Œåˆ›å»ºæ–°é“¾ä»¥ä¾¿åç»­ç‰ˆæœ¬ç®¡ç†
      if (!state.currentChainId) {
        const baseType = (optimizationMode.value === 'system' ? 'optimize' : 'userOptimize') as PromptRecordType
        const recordData = {
          id: uuidv4(),
          originalPrompt: state.prompt,
          optimizedPrompt,
          type: baseType,
          modelKey,
          templateId,
          timestamp: Date.now(),
          metadata: {
            optimizationMode: optimizationMode.value,
            functionMode: functionMode.value,
            localEdit: true,
            localEditSource: source || 'manual',
          }
        }
        const newRecord = await historyManager.value.createNewChain(recordData)
        state.currentChainId = newRecord.chainId
        state.currentVersions = newRecord.versions
        state.currentVersionId = newRecord.currentRecord.id
        return
      }

      const updatedChain = await historyManager.value.addIteration({
        chainId: state.currentChainId,
        originalPrompt: state.prompt,
        optimizedPrompt,
        modelKey,
        templateId,
        iterationNote: note || (source === 'patch' ? 'Direct fix' : 'Manual edit'),
        metadata: {
          optimizationMode: optimizationMode.value,
          functionMode: functionMode.value,
          localEdit: true,
          localEditSource: source || 'manual',
        }
      })

      state.currentVersions = updatedChain.versions
      state.currentVersionId = updatedChain.currentRecord.id
    } catch (error: unknown) {
      console.error('[usePromptOptimizer] ä¿å­˜æœ¬åœ°ä¿®æ”¹å¤±è´¥:', error)
      toast.warning(t('toast.warning.saveHistoryFailed'))
    }
  }
  
  // åˆ‡æ¢ç‰ˆæœ¬ - å¢å¼ºç‰ˆæœ¬ï¼Œç¡®ä¿å¼ºåˆ¶æ›´æ–°
  state.handleSwitchVersion = async (version: PromptChain['versions'][number]) => {
    // å¼ºåˆ¶æ›´æ–°å†…å®¹ï¼Œç¡®ä¿UIåŒæ­¥
    state.optimizedPrompt = version.optimizedPrompt;
    state.currentVersionId = version.id;

    // ç­‰å¾…ä¸€ä¸ªå¾®ä»»åŠ¡ç¡®ä¿çŠ¶æ€æ›´æ–°å®Œæˆ
    await nextTick()
  }

  /**
   * åˆ†æåŠŸèƒ½ï¼šæ¸…ç©ºç‰ˆæœ¬é“¾ï¼Œåˆ›å»º V0ï¼ˆåŸå§‹ç‰ˆæœ¬ï¼‰
   * - ä¸å†™å…¥å†å²è®°å½•
   * - åªåˆ›å»ºå†…å­˜ä¸­çš„è™šæ‹Ÿ V0 ç‰ˆæœ¬
   */
  state.handleAnalyze = () => {
    if (!state.prompt.trim()) return

    // ç”Ÿæˆè™šæ‹Ÿçš„ V0 ç‰ˆæœ¬è®°å½•ï¼ˆä¸å†™å…¥å†å²ï¼‰
    const virtualV0Id = uuidv4()
    const virtualV0: PromptChain['versions'][number] = {
      id: virtualV0Id,
      chainId: '', // è™šæ‹Ÿé“¾ï¼Œä¸å…³è”çœŸå®å†å²
      version: 0,
      originalPrompt: state.prompt,
      optimizedPrompt: state.prompt, // V0 çš„ä¼˜åŒ–å†…å®¹å°±æ˜¯åŸå§‹å†…å®¹
      type: 'optimize',
      timestamp: Date.now(),
      modelKey: '',
      templateId: '',
    }

    // æ¸…ç©ºæ—§é“¾æ¡ï¼Œè®¾ç½®æ–°çš„ V0
    state.currentChainId = ''
    state.currentVersions = [virtualV0]
    state.currentVersionId = virtualV0Id
    state.optimizedPrompt = state.prompt
  }

  // æ³¨æ„ï¼šæ¨¡æ¿åˆå§‹åŒ–ã€é€‰æ‹©ä¿å­˜å’Œå˜åŒ–ç›‘å¬ç°åœ¨éƒ½ç”± useTemplateManager è´Ÿè´£

  // è¿”å› reactive å¯¹è±¡ï¼Œè€Œä¸æ˜¯åŒ…å«å¤šä¸ª ref çš„å¯¹è±¡
  return state
} 
